{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OR_GATE_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W9CF0WctSuXa"
      },
      "outputs": [],
      "source": [
        "# 필요한 library\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비하기\n",
        "x = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
        "y = np.array([[0],[1],[1],[1]])\n",
        "\n",
        "## data로 부터 직접 tensor 생성\n",
        "x = torch.tensor(x,  dtype=torch.float) \n",
        "y = torch.tensor(y,  dtype=torch.float)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL-nbrWpSwE4",
        "outputId": "33d1f00b-c8a8-4cf4-9707-a7c0f4625783"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단층 퍼셉트론 구성하기\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "bsWa_5ZpSw-a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조 보기\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K36gwj2fSzPe",
        "outputId": "6050a301-48cf-47aa-f6da-532020e53edb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(),lr=0.01) # torch optimizer는 lr이 지정되어 있어야 함.\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "losses = []"
      ],
      "metadata": {
        "id": "RyJjSufwS0PB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  optimizer.zero_grad()\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred.view_as(y),y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  losses.append(loss.item())\n",
        "  print(loss)\n",
        "\n",
        "y_pred = model(x)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJuMtpgfS1Pr",
        "outputId": "fae0e717-3791-4bb1-b50e-634cf43798eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3954, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3792, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3639, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3495, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3360, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3233, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3114, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.3002, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2896, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2796, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2703, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2614, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2531, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2453, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2379, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2244, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2182, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2124, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2069, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.2017, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1922, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1878, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1837, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1798, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1760, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1725, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1661, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1631, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1576, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1550, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1526, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1503, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1481, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1461, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1441, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1422, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1370, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1355, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1340, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1325, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1299, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1286, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1230, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1211, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1201, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1193, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1184, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1168, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1160, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1124, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0977, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0970, grad_fn=<MseLossBackward0>)\n",
            "tensor([[0.3652],\n",
            "        [0.5159],\n",
            "        [0.9863],\n",
            "        [1.1370]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YqazBTKS22L",
        "outputId": "1e22b8c5-ec38-4478-d374-e4cf7e87d746"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 32.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy\n",
        "acc = Accuracy()\n",
        "y = np.array([[0],[1],[1],[1]])\n",
        "y = torch.tensor(x,  dtype=torch.int) \n",
        "acc(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKuDJWqNS3v_",
        "outputId": "634d99f4-b62a-4184-f10e-df396f1f3377"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}